{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_5(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(LeNet_5,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,6,5,stride=1,padding=2),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(6,16,5,1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,120,5,1),     \n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,10), \n",
    "        )\n",
    "\n",
    "    def forward(self,input):\n",
    "        x = self.conv(input)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        x = nn.Softmax(dim=1)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MNIST(root='./test',train=False,download=False,transform=transforms.ToTensor())\n",
    "\n",
    "# Umst√§ndlich with dataloader\n",
    "#test_loader = torch.utils.data.DataLoader(test_data,batch_size=1)\n",
    "\n",
    "img,label = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage = transforms.ToTensor()(img).to(device)\\n#image = image.unsqueeze(0)\\nprint(image.size())\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet_5()\n",
    "model.load_state_dict(torch.load('LeNet_5_state_dict.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for dataloader approch\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        fig, ax = plt.subplots(squeeze=False)\n",
    "        img = torch.squeeze(X,0)\n",
    "        img = torch.squeeze(img,0)\n",
    "        ax[0,0].imshow(img)\n",
    "        # (1, 1, 28, 28)\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        print(f\"predicted: {pred.argmax(1).item()}\\nactual:{y.item()}\")\n",
    "        break\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 7\n",
      "actual:7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = torch.unsqueeze(img,0).to(device)\n",
    "\n",
    "    pred = model(X)\n",
    "    print(f\"predicted: {pred.argmax(1).item()}\\nactual:{label}\")\n",
    "    fig, ax = plt.subplots(squeeze=False)\n",
    "    show_instance = torch.squeeze(img,0)\n",
    "    ax[0,0].imshow(show_instance)\n",
    "    _ = ax[0,0].set(xticklabels=[],yticklabels=[],xticks=[],yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c841516a74a887d0dc322c94a4c9096718cc31c40543db1a8dc13eb4d37cbe39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
